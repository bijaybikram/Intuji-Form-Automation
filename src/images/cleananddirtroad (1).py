# -*- coding: utf-8 -*-
"""CleanandDirtRoad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16rv41FOboT2OStr8oUAbfaGlsMR4yRHr
"""

# !pip install -U tensorflow==2.0.0-alpha0
!pip install kagglehub
!pip install tensorflow-hub
# !pip install tf_keras
!pip install -U tensorflow # Upgrade tensorflow
!pip install -U tf_keras
import tf_keras
import kagglehub
import os
import pandas as pd
import numpy as np
import tensorflow as tf
from tf_keras.callbacks import ModelCheckpoint
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from random import randint
import tensorflow_hub as hub
# import tensorflow as tf

import requests
from PIL import Image
from io import BytesIO

import matplotlib.pyplot as plt
import numpy as np

tf.__version__

# Select an Image Classification model
model_name = "035-128-classification"

# Download latest version
path = kagglehub.model_download("google/mobilenet-v2/tensorFlow2/035-128-classification")

model_handle_map = {
  model_name: path,
}

model_image_size_map = {
  "035-128-classification": 128,
}

model_handle = model_handle_map[model_name]

print(f"Selected model: {model_name} : {model_handle}")

# Download latest version
import os

image_dir = "/content/drive/MyDrive/Colab Notebooks/clean_litter/images"
if not os.path.exists(image_dir):
    print("❌ Directory does not exist:", image_dir)
else:
    print("✅ Directory exists. Listing files...")
    print(os.listdir(image_dir)[:10])  # Print first 10 files

# Use image_dir instead of images_path
print("Path to dataset files:", image_dir)

labels_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/clean_litter/metadata.csv')
print('\n\nlabels dataframe: \n', labels_df.head(), '\n\n')

class_names = ('clean', 'dirty')
num_classes = len(class_names)

img_size = (128, 128, 3)

print(f'{num_classes} classes: {class_names}\nimage size: {img_size}')


labels = []
images = []
for index, image in labels_df.iterrows(): # Iterate using iterrows to get index and row
    image_path = os.path.join(image_dir, image['filename']) # Construct full image path

    # Check if image file exists before reading
    if os.path.exists(image_path):
        img = cv2.imread(image_path, cv2.IMREAD_COLOR)
        if img is not None: # Check if image was loaded successfully
            resized_img = cv2.resize(img, img_size[0:2])[:, :, ::-1]
            images.append(np.asarray(resized_img))

            # labels will be in the form of a vector: [0, 1] or [1, 0]
            label = np.zeros(num_classes)
            label[image['label']] = 1  # Access label using column name
            labels.append(label)
        else:
            print(f"Failed to load image: {image_path}")
    else:
        print(f"Image file not found: {image_path}")

labels = np.asarray(labels)
images = np.asarray(images)

print(f'\nlabels shape: {labels.shape}')
print(f'images shape: {images.shape}')

plt.imshow(images[1])

#PROCESS IMAGE UTILITY
def preprocess_image(image):
  image = np.array(image)
  # reshape into shape [batch_size, height, width, num_channels]
  img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])
  # Use `convert_image_dtype` to convert to floats in the [0,1] range.
  image = tf.image.convert_image_dtype(img_reshaped, tf.float32)
  return image

#SHOW IMAGE UTILITY
def show_image(image, title=''):
  image_size = image.shape[1]
  w = (image_size * 6) // 320
  plt.figure(figsize=(w, w))
  plt.imshow(image[0], aspect='equal')
  plt.axis('off')
  plt.title(title)
  plt.show()

# Commented out IPython magic to ensure Python compatibility.
demoImage = preprocess_image(images[1])
classifier = hub.load(model_handle)

input_shape = demoImage.shape
warmup_input = tf.random.uniform(input_shape, 0, 1.0)
# %time warmup_logits = classifier(warmup_input).numpy()

max_dynamic_size = 512
if model_name in model_image_size_map:
  image_size = model_image_size_map[model_name]
  dynamic_size = False
  print(f"Images will be converted to {image_size}x{image_size}")
else:
  dynamic_size = True
  print(f"Images will be capped to a max size of {max_dynamic_size}x{max_dynamic_size}")

labels_file = "https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt"

#download labels and creates a maps
downloaded_file = tf.keras.utils.get_file("labels.txt", origin=labels_file)

classes = []

with open(downloaded_file) as f:
  labels = f.readlines()
  classes = [l.strip() for l in labels]

# Commented out IPython magic to ensure Python compatibility.
# Run model on image
# %time probabilities = tf.nn.softmax(classifier(demoImage)).numpy()

top_5 = tf.argsort(probabilities, axis=-1, direction="DESCENDING")[0][:5].numpy()
np_classes = np.array(classes)

# Some models include an additional 'background' class in the predictions, so
# we must account for this when reading the class labels.
includes_background_class = probabilities.shape[1] == 1001

for i, item in enumerate(top_5):
  class_index = item if includes_background_class else item + 1
  line = f'({i+1}) {class_index:4} - {classes[class_index]}: {probabilities[0][top_5][i]}'
  print(line)

show_image(demoImage, '')

demoImage = preprocess_image(images[120])
show_image(demoImage, '')

# Commented out IPython magic to ensure Python compatibility.
# Run model on image
# %time probabilities = tf.nn.softmax(classifier(demoImage)).numpy()

top_5 = tf.argsort(probabilities, axis=-1, direction="DESCENDING")[0][:5].numpy()
np_classes = np.array(classes)

includes_background_class = probabilities.shape[1] == 1001

for i, item in enumerate(top_5):
  class_index = item if includes_background_class else item + 1
  line = f'({i+1}) {class_index:4} - {classes[class_index]}: {probabilities[0][top_5][i]}'
  print(line)

show_image(demoImage, '')

import kagglehub

model_name = "035-128-classification"

# Download latest version
path = kagglehub.model_download("google/mobilenet-v2/tensorFlow2/035-128-feature-vector")
#NOTICE HOW WE ARE USING FEATURE VECTOR FOR THIS STEP AND NOT CLASSIFIER
model_handle_map = {
  model_name: path,
}

model_image_size_map = {
  "035-128-classification": 128,
}

model_handle = model_handle_map.get(model_name)
pixels = model_image_size_map.get(model_name, 128)

print(f"Selected model: {model_name} : {model_handle}")

IMAGE_SIZE = (pixels, pixels)
print(f"Input size {IMAGE_SIZE}")

BATCH_SIZE = 4

# Display 16 pictures from the dataset
fig, axs = plt.subplots(4, 4, figsize=(10, 10))

for x in range(4):
    for y in range(4):
        i = randint(0, len(images))

        axs[x][y].imshow(images[i])

        # delete x and y ticks and set x label as picture label
        axs[x][y].set_xticks([])
        axs[x][y].set_yticks([])
        axs[x][y].set_xlabel(class_names[np.argmax(labels[i])])

plt.show()

image_dir = "/content/drive/MyDrive/Colab Notebooks/clean_litter/images"


labels_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/clean_litter/metadata.csv')
print('\n\nlabels dataframe: \n', labels_df.head(), '\n\n')

class_names = ('clean', 'dirty')
num_classes = len(class_names)

img_size = (128, 128, 3)

print(f'{num_classes} classes: {class_names}\nimage size: {img_size}')


labels = []
images = []
for index, image in labels_df.iterrows(): # Iterate using iterrows to get index and row
    image_path = os.path.join(image_dir, image['filename']) # Construct full image path

    # Check if image file exists before reading
    if os.path.exists(image_path):
        img = cv2.imread(image_path, cv2.IMREAD_COLOR)
        if img is not None: # Check if image was loaded successfully
            resized_img = cv2.resize(img, img_size[0:2])[:, :, ::-1]
            images.append(np.asarray(resized_img))

            # labels will be in the form of a vector: [0, 1] or [1, 0]
            label = np.zeros(num_classes)
            label[image['label']] = 1  # Access label using column name
            labels.append(label)
        else:
            print(f"Failed to load image: {image_path}")
    else:
        print(f"Image file not found: {image_path}")

labels = np.asarray(labels)
images = np.asarray(images)

print(f'\nlabels shape: {labels.shape}')
print(f'images shape: {images.shape}')

# DEFINE TRAIN/TEST SPLIT
X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.1, random_state=42)

print(f'train images shape: {X_train.shape}\ntrain labels shape: {y_train.shape}\n\nvalidation images shape: {X_val.shape}\nvalidation labels shape: {y_val.shape}\n')

# ImageDataGenerator for train images
train_images_generator = tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.3,
                                                                         rotation_range=15,
                                                                         zoom_range=0.3,
                                                                         vertical_flip=True,
                                                                         horizontal_flip=True)
train_images_generator = train_images_generator.flow(X_train, y=y_train, batch_size=32) # Removed .repeat()

# ImageDataGenerator for validation images
validation_images_generator = tf.keras.preprocessing.image.ImageDataGenerator(vertical_flip=True,
                                                                              horizontal_flip=True,)
validation_images_generator = validation_images_generator.flow(X_val, y=y_val, batch_size=32) # Removed .repeat()

batch_x, batch_y = next(iter(train_images_generator))
print(f"Train batch shape: {batch_x.shape}, {batch_y.shape}")

do_fine_tuning = False

print("Building model with", model_handle)
model = tf_keras.Sequential([
    # Explicitly define the input shape so the model can be properly
    # loaded by the TFLiteConverter
    tf_keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),
    hub.KerasLayer(model_handle, trainable=do_fine_tuning),
    tf_keras.layers.Dropout(rate=0.2),
    tf_keras.layers.Dense(len(class_names),
                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))
])
model.build((None,)+IMAGE_SIZE+(3,))
model.summary()

from tf_keras.callbacks import ModelCheckpoint

# creating ModelCheckpoint callback
checkpoint_callback = ModelCheckpoint('cnn_model/model{epoch:02d}.keras')

# You can use this callback during model training
# model.fit(train_data, validation_data=val_data, epochs=10, callbacks=[checkpoint_callback])

x_batch, y_batch = next(iter(validation_images_generator))
print(f"Validation batch shape: {x_batch.shape}, {y_batch.shape}")

batch_x, batch_y = next(iter(train_images_generator))
print(f"Train batch shape: {batch_x.shape}, {batch_y.shape}")

model.compile(
  optimizer='adam',
  loss=tf_keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),
  metrics=['accuracy'])

train_size = X_train.shape[0]
valid_size = X_val.shape[0]
steps_per_epoch = max(1, len(X_train) // BATCH_SIZE)
validation_steps = max(1, len(X_val) // BATCH_SIZE)
hist = model.fit(
    train_images_generator,
    epochs=20,
    verbose=1,
    steps_per_epoch=steps_per_epoch,
    validation_data=validation_images_generator,
    validation_steps=validation_steps,
    callbacks=[checkpoint_callback],
    use_multiprocessing=False,  # Prevents multiprocessing issues
    # workers=0  # Use a single worker to avoid thread deadlocks
    )

accuracy = hist.history['accuracy']
val_accuracy = hist.history['val_accuracy']

loss = hist.history['loss']
val_loss = hist.history['val_loss']

epochs = range(len(accuracy))

plt.figure()
plt.plot(epochs, accuracy, label='Training Accuracy')
plt.plot(epochs, loss, label='Training Loss')
plt.legend()
plt.title('Training Accuracy and Loss')

plt.figure()
plt.plot(epochs, val_accuracy, label='Validation Accuracy')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.legend()
plt.title('Validation Accuracy and Loss')

plt.show()

fig, axs = plt.subplots(5, 4, figsize=(12, 12))

i = 0
for x in range(5):
    for y in range(4):
        prediction = model.predict(X_val[i][None, ...], verbose=0)[0]

        axs[x][y].set_xticks([])
        axs[x][y].set_yticks([])

        if np.argmax(prediction) != np.argmax(y_val[i]):
            axs[x][y].set_xlabel(f'prediction: {class_names[np.argmax(prediction)]} | label: {class_names[np.argmax(y_val[i])]}', color='red')
        else:
            axs[x][y].set_xlabel(f'prediction: {class_names[np.argmax(prediction)]} | label: {class_names[np.argmax(y_val[i])]}')

        axs[x][y].imshow(X_val[i])

        i += 1
plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Get model predictions
y_pred = model.predict(X_val)
predicted_categories = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_val, axis=1)

# Generate classification report
print("Classification Report:")
print(classification_report(y_true, predicted_categories, target_names=class_names))

# Generate confusion matrix
cm = confusion_matrix(y_true, predicted_categories)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title("Clean and Dirt Road Classification - Confusion Matrix")
plt.show()